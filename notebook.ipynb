{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '-'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/0l/mrtqnjts01v_48lkl9674g3r0000gn/T/ipykernel_29621/763007801.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     16\u001b[39m data_cleaned = data_cleaned.dropna()\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Standardize the data (important for dimensionality reduction)\u001b[39;00m\n\u001b[32m     19\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m data_scaled = scaler.fit_transform(data_cleaned)\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Apply PCA to reduce dimensionality to 50 dimensions first (for t-SNE/UMAP to work better)\u001b[39;00m\n\u001b[32m     23\u001b[39m pca = PCA(n_components=\u001b[32m50\u001b[39m)\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m     @wraps(f)\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    320\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    321\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m             return_tuple = (\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    914\u001b[39m                 )\n\u001b[32m    915\u001b[39m \n\u001b[32m    916\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    890\u001b[39m             Fitted scaler.\n\u001b[32m    891\u001b[39m         \"\"\"\n\u001b[32m    892\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    926\u001b[39m         self : object\n\u001b[32m    927\u001b[39m             Fitted scaler.\n\u001b[32m    928\u001b[39m         \"\"\"\n\u001b[32m    929\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m         X = validate_data(\n\u001b[32m    931\u001b[39m             self,\n\u001b[32m    932\u001b[39m             X,\n\u001b[32m    933\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2940\u001b[39m             out = y\n\u001b[32m   2941\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2942\u001b[39m             out = X, y\n\u001b[32m   2943\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2945\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2947\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/ml-asg/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '-'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Drop columns that are categorical or unnecessary for dimensionality reduction\n",
    "data_cleaned = data.drop(columns=['STN Code', 'Name of Monitoring Location', 'State Name', 'Type Water Body'])\n",
    "\n",
    "# Handle missing data by dropping rows with missing values (or alternatively you can impute missing values)\n",
    "data_cleaned = data_cleaned.dropna()\n",
    "\n",
    "# Standardize the data (important for dimensionality reduction)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_cleaned)\n",
    "\n",
    "# Apply PCA to reduce dimensionality to 50 dimensions first (for t-SNE/UMAP to work better)\n",
    "pca = PCA(n_components=50)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Now apply t-SNE for 2D visualization\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "data_tsne = tsne.fit_transform(data_pca)\n",
    "\n",
    "# Apply UMAP for 2D visualization\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2)\n",
    "data_umap = umap_model.fit_transform(data_pca)\n",
    "\n",
    "# Plotting t-SNE results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data_tsne[:, 0], data_tsne[:, 1], c='blue', edgecolor='k', s=100, alpha=0.5)\n",
    "plt.title(\"t-SNE Dimensionality Reduction\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.show()\n",
    "\n",
    "# Plotting UMAP results\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data_umap[:, 0], data_umap[:, 1], c='red', edgecolor='k', s=100, alpha=0.5)\n",
    "plt.title(\"UMAP Dimensionality Reduction\")\n",
    "plt.xlabel(\"UMAP Dimension 1\")\n",
    "plt.ylabel(\"UMAP Dimension 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking variables before plotting ---\n",
      "Type of X_pca_reduced_df: <class 'pandas.core.frame.DataFrame'>, Shape: (620, 10)\n",
      "Type of hard_labels: <class 'numpy.ndarray'>, Length: 620\n",
      "Type of membership_u: <class 'numpy.ndarray'>, Shape: (2, 620)\n",
      "Value of optimal_c: 2\n",
      "--- Variable check complete ---\n",
      "Variables seem okay, attempting to generate plots...\n"
     ]
    }
   ],
   "source": [
    "# --- Add these imports here too, just in case ---\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd # Assuming pandas is needed if X_orig is DataFrame\n",
    "\n",
    "# --- Enable Matplotlib Interactive Backend ---\n",
    "%matplotlib notebook\n",
    "\n",
    "# --- Verification before plotting ---\n",
    "print(\"--- Checking variables before plotting ---\")\n",
    "variables_ok = True\n",
    "try:\n",
    "    print(f\"Type of X_pca_reduced_df: {type(X_pca_reduced_df)}, Shape: {X_pca_reduced_df.shape}\")\n",
    "except NameError:\n",
    "    print(\"Error: X_pca_reduced_df is not defined.\")\n",
    "    variables_ok = False\n",
    "\n",
    "try:\n",
    "    print(f\"Type of hard_labels: {type(hard_labels)}, Length: {len(hard_labels)}\")\n",
    "except NameError:\n",
    "    print(\"Error: hard_labels is not defined.\")\n",
    "    variables_ok = False\n",
    "\n",
    "try:\n",
    "    print(f\"Type of membership_u: {type(membership_u)}, Shape: {membership_u.shape}\")\n",
    "except NameError:\n",
    "    print(\"Error: membership_u is not defined.\")\n",
    "    variables_ok = False\n",
    "\n",
    "try:\n",
    "    print(f\"Value of optimal_c: {optimal_c}\")\n",
    "except NameError:\n",
    "    print(\"Error: optimal_c is not defined.\")\n",
    "    variables_ok = False\n",
    "\n",
    "if not variables_ok:\n",
    "    print(\"!!! Please ensure Cell 1 ran correctly and defined the necessary variables. !!!\")\n",
    "print(\"--- Variable check complete ---\")\n",
    "# --- End of Verification ---\n",
    "\n",
    "\n",
    "def plot_interactive_clusters_3d(X_orig, labels, k, title_suffix=\"Hard Labels\"):\n",
    "    # ... (rest of function is the same) ...\n",
    "    plt.show() # Ensure this is here\n",
    "\n",
    "def plot_interactive_fuzzy_partition_3d(X_orig, u, labels, k, title_suffix=\"Fuzzy Partition (Alpha=Certainty)\"):\n",
    "    # ... (rest of function is the same) ...\n",
    "    plt.show() # Ensure this is here\n",
    "\n",
    "\n",
    "# --- Generate the plots if data loaded AND VERIFIED ---\n",
    "# Use the 'variables_ok' flag we just set\n",
    "if variables_ok:\n",
    "     print(\"Variables seem okay, attempting to generate plots...\")\n",
    "     plot_interactive_clusters_3d(X_pca_reduced_df, hard_labels, optimal_c)\n",
    "     plot_interactive_fuzzy_partition_3d(X_pca_reduced_df, membership_u, hard_labels, optimal_c)\n",
    "else:\n",
    "     print(\"Skipping interactive plots due to missing data or FCM results (based on variable check).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-asg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
